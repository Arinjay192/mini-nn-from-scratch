{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Introduction to Deep Learning\n## Logistic Regression \nLogistic Regression is a fundamental supervised learning algorithm used for binary classification tasks. Despite its name, it's used for classification, not regression. Logistic Regression models the probability that a given input belongs to a particular class.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Implementation Steps\n1. Data Pre-processing\n2. Parameter Initialization\n3. Forward Propagation:\n4. Cost Calculation\n5. Backward Propagation\n6. Parameter Update\n7. Model Evaluation",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let's import libraries we've already learnt and will use",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport matplotlib.pyplot as plt",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "Matplotlib is building the font cache; this may take a moment.\n"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "### 1. Data Pre-Processing\nThe dataset contains information that may be used for diagnosing or predicting the presence of heart disease in individuals. It comprises various clinical and demographic features that are commonly considered in cardiovascular health assessment. Understanding and analyzing these features can aid in developing predictive models or understanding the factors associated with heart disease.  \nThe first 13 fields are \n- Age\n- Sex\n- Chest Pain Type (cp)\n- Resting Blood Pressure (trestbps)\n- Serum Cholesterol Level (chol)\n- Fasting Blood Sugar (fbs)\n- Resting Electrocardiographic Results (restecg)\n- Maximum Heart Rate Achieved (thalach)\n- Exercise-Induced Angina (exang)\n- ST Depression Induced by Exercise Relative to Rest (oldpeak)\n- Slope of the Peak Exercise ST Segment (slope)\n- Number of Major Vessels Colored by Fluoroscopy (ca)\n- Thalassemia (thal)  \n\nAnd the 14th field is 'target' and is either 0 or 1. The \"target\" field refers to the presence of heart disease in the patient. It is integer valued 0 = no disease and 1 = disease.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "First, we import data from the csv file provided",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dataset_raw = np.genfromtxt(\"heart.csv\", dtype=\"str\", delimiter=\",\")\nprint(dataset_raw.shape)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "(1026, 14)\n"
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "This dataset have headers that we don't need for logistic regression model. That is there for us to understand what the values denote  \nWe seperate the headers",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "headers = dataset_raw[0, :]\nprint(headers)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "['age' 'sex' 'cp' 'trestbps' 'chol' 'fbs' 'restecg' 'thalach' 'exang'\n 'oldpeak' 'slope' 'ca' 'thal' 'target']\n"
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "And now we get rest of the numerical data and cast them as `float` data type instead of `string`",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dataset = dataset_raw[1:, :]\ndataset = dataset.astype(float)\nprint(dataset)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[52.  1.  0. ...  2.  3.  0.]\n [53.  1.  0. ...  0.  3.  0.]\n [70.  1.  0. ...  0.  3.  0.]\n ...\n [47.  1.  0. ...  1.  2.  0.]\n [50.  0.  0. ...  0.  2.  1.]\n [54.  1.  0. ...  1.  3.  0.]]\n"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "In this dataset, the first 13 columns represent the features, while the 14th column indicates whether the individual has the disease or not based on those features. Here we seperate the dataset into X (feature vector) and Y (output vector).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = dataset[:, :13]\nY = dataset[:, 13]\nprint(X.shape)\nprint(Y.shape)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "(1025, 13)\n(1025,)\n"
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "Shape of X here is $(m, n_x)$, but we want it to have $shape = (n_x, m)$",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = X.T\nprint(X.shape)\nprint(Y.shape)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "(13, 1025)\n(1025,)\n"
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": "#### Looks good\nFinally, we have 1025 examples of 13 features and 1 output  \nFrom the notation you have studied till now  \n$$\n\\begin{align*}\nn_x &= 13 \\\\\nn_y &= 1 \\\\\nm &= 1025\n\\end{align*}\n$$\nNow we can proceed to making our logistic regression model and train our model  \nBut, we have one problem to deal with. How would we know if our model is doing good and if it is, how good is it?  \nThat is why from the 1025 examples we have, we'll keep some data aside and use it to test our model's prediction  \nLet's keep 80% of the data for training and 20% of the data for testing our model",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# get index to split data in 80:20 ratio\nindex = int(0.8 * X.shape[1])\n\n# split the data\nX_train = X[:, :index]\nX_test = X[:, index:]\n\nY_train = Y[:index]\nY_test = Y[index:]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "Let's print shapes for our dataset",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"X_train shape\", X_train.shape)\nprint(\"Y_train shape\", Y_train.shape)\nprint(\"Number of training examples =\", Y_train.shape[0])\nprint(\"-\"*40)\nprint(\"X_test shape\", X_test.shape)\nprint(\"Y_test shape\", Y_test.shape)\nprint(\"Number of testing examples =\", Y_test.shape[0])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "X_train shape (13, 820)\nY_train shape (820,)\nNumber of training examples = 820\n----------------------------------------\nX_test shape (13, 205)\nY_test shape (205,)\nNumber of testing examples = 205\n"
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": "## Logistic Regression \n#### Forward Propagation\n$$\nZ = W^T X + b  \\\\\nA = sigmoid(X) \\\\\n$$\n#### Calculate Cost\n$$\nJ = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})\n$$\n#### Backward Propagation\n$$ \\partial W = \\frac{\\partial J}{\\partial W} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n$$ \\partial b = \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$\n#### Parameter Updation\n$$ W = W - \\alpha \\text{ } \\partial W $$\n$$ b = b - \\alpha \\text{ } \\partial b $$",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### 2. Initializing parameters\n**Assignment**: Complete the function for parameter initialization in the cell below. \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def init_params(num_features):\n    \"\"\"\n    This function creates a vector of zeros of shape (num_features, 1) for w and initializes b to 0.\n\n    Returns:\n    W -- initialized vector of shape (num_features, 1)\n    b -- initialized scalar (corresponds to the bias)\n    \"\"\"\n    W = np.zeros((num_features, 1))\n    b = 0\n\n    return W, b\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": "#### **Helper Function**: Sigmoid\n**Assignment**: Complete the function for calculating sigmoid in the cell below. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def sigmoid(x):\n    \"\"\"\n    Compute the sigmoid of x\n\n    Return:\n    s -- sigmoid(x)\n    \"\"\"\n    s = 1 / (1 + np.exp(-x))\n    return s\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": "### 3. Forward Propagation\n$$\nZ = W^T X + b  \\\\\nA = sigmoid(X) \\\\\n$$\n**Assignment**: Complete the function implementing forward propagation in the cell below. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def forward_prop(w, b, X):\n    \"\"\"\n    Compute forward propagation\n\n    Return:\n    A -- activation\n    \"\"\"\n    Z = np.dot(w.T, X) + b\n    A = sigmoid(Z)\n\n    return A\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": "### 4. Calculate Cost\n$$\nJ = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})\n$$\n**Assignment**: Complete the function to calculate cost in the cell below. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def calculate_loss(A, Y):\n    \"\"\"\n    Calculate cross entropy loss between calculated values (A) and actual values (Y)\n\n    Return:\n    cost -- cost calculated\n    \"\"\"\n    # get number of examples\n    m = Y.shape[0]\n    \n    # calculate cost\n    cost = (-1 / m) * np.sum(Y * np.log(A + 1e-8) + (1 - Y) * np.log(1 - A + 1e-8))\n\n    # this will remove any useless dimensions from cost\n    cost = np.squeeze(cost)\n\n    return cost\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": "### 5. Backward Propagation\n$$ \\partial W = \\frac{\\partial J}{\\partial W} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n$$ \\partial b = \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$\n**Assignment**: Complete the function to compute gradients in the cell below. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def backward_prop(A, X, Y):\n    \"\"\"\n    Calculate gradients dW and db\n\n    Return:\n    dW -- gradient of the loss with respect to w, thus same shape as w\n    db -- gradient of the loss with respect to b, thus same shape as b\n    \"\"\"\n    # get number of examples\n    m = X.shape[1]\n\n    # calculate gradients\n    dZ = A - Y                      # shape: (1, m)\n    dW = (1/m) * np.dot(X, dZ.T)   # shape: (num_features, 1)\n    db = (1/m) * np.sum(dZ)        # scalar\n\n    return dW, db\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": "### 6. Parameter Updation\n$$ W = W - \\alpha \\text{ } \\partial W $$\n$$ b = b - \\alpha \\text{ } \\partial b $$\n**Assignment**: Complete the function to update parameters in the cell below. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def update_params(W, b, dW, db, learning_rate):\n    \"\"\"\n    Update params W and b from their gradients\n\n    Return:\n    W -- updated W\n    b -- updated b\n    \"\"\"\n    W = W - learning_rate * dW\n    b = b - learning_rate * db\n\n    return W, b\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": "As our model's forward propagation return value calculated from sigmoid function, it lies between 0 and 1  \nWe can say output should be 1 when A > 0.5 and 0 when A < 0.5  \nLet's implement a function that will do this for us in vectorized way\n### Predict ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def predict(W, b, X):\n  A = forward_prop(W, b, X)\n  Y_pred = (A>=0.5)*1.0\n  return Y_pred",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": "### Let's compile all these function to implement training loop for our model\nYou don't need to write any math here, just put all the functions you've written above in the right sequence",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def train(X, Y, num_iterations=10000, learning_rate=0.0001, print_cost=True):\n    # initialize parameters\n    W = np.zeros((X.shape[0], 1))\n    b = 0\n\n    costs = []\n\n    for i in range(num_iterations):\n        # forward propagation\n        A = forward_prop(W, b, X)\n\n        # calculate cost\n        cost = calculate_loss(A, Y)\n\n        # backward propagation\n        dw, db = backward_prop(A, X, Y)\n\n        # parameter updation\n        W, b = update_params(W, b, dw, db, learning_rate)\n\n        # store cost every 100 iterations\n        if i % 100 == 0:\n            costs.append(cost)\n\n        # print cost\n        if print_cost and i % 100 == 0:\n            print(f\"Cost after {i+1} iteration : {cost}\")\n\n    return W, b, costs\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": "### Let the model train",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "W, b, costs = train(X_train, Y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Cost after 1 iteration : 0.6931471605599454\nCost after 101 iteration : 0.7723672736667179\nCost after 201 iteration : 0.6739935689578312\nCost after 301 iteration : 0.6417824718467297\nCost after 401 iteration : 0.628587442128276\nCost after 501 iteration : 0.6229415031132706\nCost after 601 iteration : 0.6201697230695079\nCost after 701 iteration : 0.6184454278495893\nCost after 801 iteration : 0.6171017170407714\nCost after 901 iteration : 0.6159022833821755\nCost after 1001 iteration : 0.6147637062715814\nCost after 1101 iteration : 0.6136560182087498\nCost after 1201 iteration : 0.612567877205917\nCost after 1301 iteration : 0.6114944652389327\nCost after 1401 iteration : 0.6104332973348795\nCost after 1501 iteration : 0.6093827712677746\nCost after 1601 iteration : 0.6083416636881731\nCost after 1701 iteration : 0.6073089520384596\nCost after 1801 iteration : 0.6062837481916575\nCost after 1901 iteration : 0.605265270278909\nCost after 2001 iteration : 0.6042528276113867\nCost after 2101 iteration : 0.6032458102334797\nCost after 2201 iteration : 0.6022436803131718\nCost after 2301 iteration : 0.6012459644809075\nCost after 2401 iteration : 0.600252246849972\nCost after 2501 iteration : 0.5992621626413613\nCost after 2601 iteration : 0.5982753923850189\nCost after 2701 iteration : 0.5972916566752345\nCost after 2801 iteration : 0.5963107114532835\nCost after 2901 iteration : 0.5953323437847693\nCost after 3001 iteration : 0.5943563680953635\nCost after 3101 iteration : 0.5933826228268597\nCost after 3201 iteration : 0.5924109674753476\nCost after 3301 iteration : 0.5914412799743433\nCost after 3401 iteration : 0.590473454387592\nCost after 3501 iteration : 0.5895073988785452\nCost after 3601 iteration : 0.5885430339260654\nCost after 3701 iteration : 0.5875802907585801\nCost after 3801 iteration : 0.5866191099814714\nCost after 3901 iteration : 0.5856594403750413\nCost after 4001 iteration : 0.5847012378427314\nCost after 4101 iteration : 0.5837444644914906\nCost after 4201 iteration : 0.5827890878281926\nCost after 4301 iteration : 0.5818350800578487\nCost after 4401 iteration : 0.5808824174710153\nCost after 4501 iteration : 0.5799310799092914\nCost after 4601 iteration : 0.5789810502991153\nCost after 4701 iteration : 0.5780323142452813\nCost after 4801 iteration : 0.5770848596766259\nCost after 4901 iteration : 0.5761386765372704\nCost after 5001 iteration : 0.5751937565176294\nCost after 5101 iteration : 0.574250092820119\nCost after 5201 iteration : 0.573307679955131\nCost after 5301 iteration : 0.5723665135634014\nCost after 5401 iteration : 0.5714265902613778\nCost after 5501 iteration : 0.5704879075066577\nCost after 5601 iteration : 0.5695504634808917\nCost after 5701 iteration : 0.5686142569879159\nCost after 5801 iteration : 0.5676792873651636\nCost after 5901 iteration : 0.5667455544066128\nCost after 6001 iteration : 0.5658130582958225\nCost after 6101 iteration : 0.5648817995477148\nCost after 6201 iteration : 0.5639517789580071\nCost after 6301 iteration : 0.5630229975592911\nCost after 6401 iteration : 0.5620954565828898\nCost after 6501 iteration : 0.5611691574257722\nCost after 6601 iteration : 0.5602441016218476\nCost after 6701 iteration : 0.5593202908170868\nCost after 6801 iteration : 0.5583977267479723\nCost after 6901 iteration : 0.5574764112228464\nCost after 7001 iteration : 0.5565563461057894\nCost after 7101 iteration : 0.5556375333026894\nCost after 7201 iteration : 0.5547199747492398\nCost after 7301 iteration : 0.5538036724005971\nCost after 7401 iteration : 0.5528886282225004\nCost after 7501 iteration : 0.551974844183664\nCost after 7601 iteration : 0.5510623222492705\nCost after 7701 iteration : 0.5501510643754386\nCost after 7801 iteration : 0.5492410725045388\nCost after 7901 iteration : 0.5483323485612381\nCost after 8001 iteration : 0.5474248944492113\nCost after 8101 iteration : 0.5465187120484059\nCost after 8201 iteration : 0.5456138032128172\nCost after 8301 iteration : 0.5447101697687037\nCost after 8401 iteration : 0.5438078135131975\nCost after 8501 iteration : 0.542906736213255\nCost after 8601 iteration : 0.5420069396049263\nCost after 8701 iteration : 0.5411084253929029\nCost after 8801 iteration : 0.5402111952503172\nCost after 8901 iteration : 0.539315250818775\nCost after 9001 iteration : 0.538420593708604\nCost after 9101 iteration : 0.5375272254992975\nCost after 9201 iteration : 0.5366351477401542\nCost after 9301 iteration : 0.5357443619510911\nCost after 9401 iteration : 0.5348548696236396\nCost after 9501 iteration : 0.5339666722221106\nCost after 9601 iteration : 0.5330797711849378\nCost after 9701 iteration : 0.5321941679261954\nCost after 9801 iteration : 0.5313098638373012\nCost after 9901 iteration : 0.5304268602889047\n"
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": "Let's plot costs to see how our model was converging",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.plot(costs)\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": "### 7. Model Evaluation\nLet's check accuracy on train and test sets",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"Train accuracy: {} %\".format(100 - np.mean(np.abs(predict(W, b, X_train) - Y_train)) * 100))\nprint(\"Test accuracy: {} %\".format(100 - np.mean(np.abs(predict(W, b, X_test) - Y_test)) * 100))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Train accuracy: 73.29268292682926 %\nTest accuracy: 71.21951219512195 %\n"
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": "\nIncreasing the number of iterations can improve training accuracy, but there's a risk of overfitting. Overfitting occurs when the model learns to fit the training data too closely, capturing noise or irrelevant patterns that don't generalize well to unseen data. In such cases, while the training accuracy continues to increase, the test accuracy may plateau or even decrease.\n\nTo address overfitting, techniques like regularization and model complexity reduction are employed. Additionally, the transition to deep neural networks offers more sophisticated methods for improving accuracies, even in the presence of overfitting.",
      "metadata": {}
    }
  ]
}