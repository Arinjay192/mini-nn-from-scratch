{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "9f113a05-579b-4a97-a128-f998405bd87c",
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n# w this we read and prepare the dataset (iris)\ndef load_iris_data():\n    data = pd.read_csv(\"iris.csv\")\n    labels = data[\"species\"].factorize()[0]\n    features = data.iloc[:, :4].values\n    scaler = StandardScaler()\n    features = scaler.fit_transform(features)\n    X_train, X_dev, y_train, y_dev = train_test_split(\n        features, labels, test_size=0.2, random_state=42, stratify=labels\n    )\n    return X_train.T, X_dev.T, y_train, y_dev\n\nX_train, X_dev, y_train, y_dev = load_iris_data()\nprint(\"Train shape:\", X_train.shape)\nprint(\"Dev shape:\", X_dev.shape)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Train shape: (4, 120)\nDev shape: (4, 30)\n"
        }
      ],
      "execution_count": 13
    },
    {
      "id": "663c3ee7-2c8f-4764-bd52-5a26f48b00f5",
      "cell_type": "code",
      "source": "# These functions help the model learn patterns\ndef relu(z):\n    return np.maximum(0, z)\n\ndef relu_derivative(z):\n    return (z > 0).astype(float)\n\ndef softmax(z):\n    shifted_z = z - np.max(z, axis=0, keepdims=True)\n    exp_values = np.exp(shifted_z)\n    return exp_values / np.sum(exp_values, axis=0, keepdims=True)\n\ndef convert_to_one_hot(y, num_classes=3):\n    m = y.shape[0]\n    one_hot_matrix = np.zeros((num_classes, m))\n    one_hot_matrix[y, np.arange(m)] = 1\n    return one_hot_matrix\n\ndef compute_accuracy(predictions, labels):\n    return np.mean(predictions == labels) * 100\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "id": "e71d8ed4-01b4-4ac5-b1fc-33fa9f3d475f",
      "cell_type": "code",
      "source": "# now We randomly create weights and biases\ndef initialize_parameters(input_size, hidden_size, output_size):\n    np.random.seed(42)\n    weights_1 = np.random.uniform(-0.5, 0.5, size=(hidden_size, input_size))\n    bias_1 = np.zeros((hidden_size, 1))\n    weights_2 = np.random.uniform(-0.5, 0.5, size=(output_size, hidden_size))\n    bias_2 = np.zeros((output_size, 1))\n    return {\n        \"W1\": weights_1,\n        \"b1\": bias_1,\n        \"W2\": weights_2,\n        \"b2\": bias_2\n    }\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "id": "27838ed4-4a6e-4111-89b3-3f6d0f18dc00",
      "cell_type": "code",
      "source": "#forward propagation through the network\ndef forward_pass(parameters, input_data):\n    w1 = parameters[\"W1\"]\n    b1 = parameters[\"b1\"]\n    w2 = parameters[\"W2\"]\n    b2 = parameters[\"b2\"]\n\n    z1 = np.dot(w1, input_data) + b1\n    a1 = relu(z1)\n    z2 = np.dot(w2, a1) + b2\n    a2 = softmax(z2)\n\n    cache = {\n        \"Z1\": z1,\n        \"A1\": a1,\n        \"Z2\": z2,\n        \"A2\": a2\n    }\n    return a2, cache\n\ndef backward_pass(parameters, cache, input_data, true_output):\n    m = input_data.shape[1]\n    w2 = parameters[\"W2\"]\n    a1 = cache[\"A1\"]\n    a2 = cache[\"A2\"]\n\n    dz2 = a2 - true_output\n    dw2 = np.dot(dz2, a1.T) / m\n    db2 = np.sum(dz2, axis=1, keepdims=True) / m\n\n    dz1 = np.dot(w2.T, dz2) * relu_derivative(cache[\"Z1\"])\n    dw1 = np.dot(dz1, input_data.T) / m\n    db1 = np.sum(dz1, axis=1, keepdims=True) / m\n\n    gradients = {\n        \"dW1\": dw1,\n        \"db1\": db1,\n        \"dW2\": dw2,\n        \"db2\": db2\n    }\n    return gradients\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "id": "cef53c62-abdd-4655-942d-c480a9ab1332",
      "cell_type": "code",
      "source": "# We use the gradients to adjust the model\ndef update_parameters(parameters, gradients, learning_rate):\n    parameters[\"W1\"] -= learning_rate * gradients[\"dW1\"]\n    parameters[\"b1\"] -= learning_rate * gradients[\"db1\"]\n    parameters[\"W2\"] -= learning_rate * gradients[\"dW2\"]\n    parameters[\"b2\"] -= learning_rate * gradients[\"db2\"]\n    return parameters\n\ndef train_model(X_train, y_train, X_dev, y_dev,\n                hidden_size=10, iterations=1000, learning_rate=0.05, print_interval=100):\n\n    input_size = X_train.shape[0]\n    output_size = len(np.unique(y_train))\n    parameters = initialize_parameters(input_size, hidden_size, output_size)\n\n    Y_train = convert_to_one_hot(y_train, output_size)\n    Y_dev = convert_to_one_hot(y_dev, output_size)\n\n    for i in range(1, iterations + 1):\n        predictions, cache = forward_pass(parameters, X_train)\n        gradients = backward_pass(parameters, cache, X_train, Y_train)\n        parameters = update_parameters(parameters, gradients, learning_rate)\n\n        if i % print_interval == 0 or i == 1:\n            train_predictions = np.argmax(predictions, axis=0)\n            dev_predictions = np.argmax(forward_pass(parameters, X_dev)[0], axis=0)\n            print(\"Iteration\", i)\n            print(\"Train Accuracy:\", compute_accuracy(train_predictions, y_train))\n            print(\"Dev Accuracy:\", compute_accuracy(dev_predictions, y_dev))\n            print()\n\n    return parameters\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "id": "55d59528-7239-4e5f-8a26-975940135ff9",
      "cell_type": "code",
      "source": "# finally we test the model on a single sample\ntrained_parameters = train_model(X_train, y_train, X_dev, y_dev,\n                                 hidden_size=10, iterations=1000, learning_rate=0.05)\n\nsample_index = 0\nsample_input = X_dev[:, sample_index:sample_index+1]\ntrue_output = y_dev[sample_index]\npredicted_output = np.argmax(forward_pass(trained_parameters, sample_input)[0])\n\nprint()\nprint(\"Sample\", sample_index)\nprint(\"Predicted:\", predicted_output)\nprint(\"Actual:\", true_output)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Iteration 1\nTrain Accuracy: 21.666666666666668\nDev Accuracy: 20.0\n\nIteration 100\nTrain Accuracy: 86.66666666666667\nDev Accuracy: 76.66666666666667\n\nIteration 200\nTrain Accuracy: 93.33333333333333\nDev Accuracy: 90.0\n\nIteration 300\nTrain Accuracy: 95.83333333333334\nDev Accuracy: 93.33333333333333\n\nIteration 400\nTrain Accuracy: 96.66666666666667\nDev Accuracy: 96.66666666666667\n\nIteration 500\nTrain Accuracy: 96.66666666666667\nDev Accuracy: 96.66666666666667\n\nIteration 600\nTrain Accuracy: 97.5\nDev Accuracy: 96.66666666666667\n\nIteration 700\nTrain Accuracy: 97.5\nDev Accuracy: 96.66666666666667\n\nIteration 800\nTrain Accuracy: 97.5\nDev Accuracy: 96.66666666666667\n\nIteration 900\nTrain Accuracy: 97.5\nDev Accuracy: 96.66666666666667\n\nIteration 1000\nTrain Accuracy: 97.5\nDev Accuracy: 96.66666666666667\n\n\nSample 0\nPredicted: 0\nActual: 0\n"
        }
      ],
      "execution_count": 18
    },
    {
      "id": "0a045455-62a6-412e-ba57-8607559f1675",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4b942ae0-8ffa-430c-82d0-29843cb5f0a0",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}